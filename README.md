# Product Search AI Agent

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This project implements a sophisticated, multi-agent system designed for comprehensive product and topic research. By leveraging the power of CrewAI and FastAPI, it orchestrates specialized AI agents to perform web searches, scrape relevant data, and compile detailed reports. The system is built to be modular and extensible, allowing for dynamic execution of different research "crews" through a simple API endpoint.

## âœ¨ Features

*   **Multi-Agent System:** Utilizes a crew of specialized AI agents for different tasks:
    *   **Search Agent:** Finds relevant information using advanced search tools.
    *   **Web Scraping Agent:** Extracts detailed data from specified URLs.
    *   **Reporting Agent:** Analyzes the gathered information and generates a comprehensive HTML report.
*   **Dynamic Crew Execution:** Run different pre-configured agent crews via a single API endpoint.
*   **Modern Tech Stack:** Built with FastAPI for a high-performance, asynchronous API.
*   **Powerful Integrations:**
    *   **CrewAI:** For orchestrating autonomous AI agents.
    *   **Tavily:** For optimized AI search results.
    *   **ScrapeGraph-AI:** For intelligent web scraping.
    *   **Groq & OpenAI:** Support for multiple LLM providers.
    *   **AgentOps:** For monitoring and observability of agent performance.
*   **Extensible by Design:** Easily add new agents, tools, and crews to expand capabilities.

## ğŸ“‚ Project Structure

The project follows a clean and modular structure to separate concerns:

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/         # Definitions for individual AI agents
â”‚   â”œâ”€â”€ api/            # FastAPI routers and endpoints
â”‚   â”œâ”€â”€ app/            # Core application logic and clients (LLM, AgentOps)
â”‚   â”œâ”€â”€ config/         # Configuration files for crews and settings
â”‚   â”œâ”€â”€ crew/           # Crew definitions and orchestration logic
â”‚   â”œâ”€â”€ models/         # Pydantic models for data validation
â”‚   â”œâ”€â”€ tasks/          # Task definitions for the agents
â”‚   â”œâ”€â”€ tools/          # Custom tools for agents (e.g., scraping)
â”‚   â”œâ”€â”€ utils/          # Utility functions
â”‚   â””â”€â”€ main.py         # Main application entry point
â”œâ”€â”€ requirements.txt    # Project dependencies
â””â”€â”€ .env.example        # Environment variable template
```

## ğŸš€ Getting Started

### 1. Prerequisites
*   Python 3.9+
*   Git

### 2. Clone the Repository
```bash
git clone https://github.com/Joseph-Essa/Product-Search-AI-Agent.git
cd Product-Search-AI-Agent
```

### 3. Set Up a Virtual Environment
```bash
# For Windows
python -m venv venv
venv\Scripts\activate

# For macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 4. Install Dependencies
```bash
pip install -r requirements.txt
```

### 5. Configure Environment Variables
Create a `.env` file by copying the `.env.example` and fill in your API keys.

```bash
cp .env.example .env
```

Your `.env` file should look like this:
```env
# AgentOps for monitoring
AGENTOPS_API_KEY="your_agentops_api_key"

# Tavily for search
TAVILY_API_KEY="your_tavily_api_key"

# LLM Provider Keys (use at least one)
OPENAI_API_KEY="your_openai_api_key"
GROQ_API_KEY="your_groq_api_key"
```

## ğŸƒ How to Run

### 1. Start the FastAPI Server
Run the application from the root directory:
```bash
uvicorn src.main:app --reload
```
The API will be available at `http://127.0.0.1:8000`. You can access the auto-generated documentation at `http://127.0.0.1:8000/docs`.

### 2. Run a Crew
You can trigger a research crew by sending a POST request to the `/api/v1/crew/run/{crew_name}` endpoint.

Here's an example using `curl` to run the `web_scraping_crew`:
```bash
curl -X 'POST' \
  'http://127.0.0.1:8000/api/v1/crew/run/web_scraping_crew' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "topic": "https://www.scrapegraph-ai.io/",
  "crew_input": {
    "prompt": "Summarize the main features of ScrapeGraph-AI."
  }
}'
```

## ğŸ“Š Results

The primary output of the agent crews is a detailed **HTML report**. These reports are generated by the `report_author_agent` and saved in the `src/app/results/` directory. After a successful run, you can open the generated `.html` file in your browser to view the comprehensive findings.

## ğŸ–¥ï¸ Graphical User Interface (GUI)

A dedicated graphical user interface for this project is currently **under development**. The goal is to provide a more intuitive and user-friendly way to interact with the agent crews, manage tasks, and view results directly in your browser. Stay tuned for updates!

## ğŸ› ï¸ Technologies Used

*   **Backend:** FastAPI
*   **AI Orchestration:** CrewAI
*   **Data Validation:** Pydantic
*   **AI Search:** Tavily
*   **Web Scraping:** ScrapeGraph-AI
*   **LLM Providers:** OpenAI, Groq
*   **Monitoring:** AgentOps

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to open an issue or submit a pull request.

## ğŸ“„ License

This project is licensed under the MIT License.

